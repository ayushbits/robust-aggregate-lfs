{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from lstm.imdb_lstm import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "We reload the dataset with the plain text plots and the labels that reef generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labels 1920\n"
     ]
    }
   ],
   "source": [
    "dataset='imdb'\n",
    "\n",
    "from data.imdb_loader import DataLoader\n",
    "# from data.youtube_loader import DataLoader\n",
    "# from data.trec_loader import DataLoader\n",
    "# from data.sms_loader import DataLoader\n",
    "\n",
    "dl = DataLoader()\n",
    "train_primitive_matrix, val_primitive_matrix, test_primitive_matrix, train_ground, val_ground, \\\n",
    "test_ground, _, _, _, train_text, val_text, test_text = dl.load_data(dataset=dataset, split_val = 0.1)\n",
    "# _, _, _, train_ground, val_ground, test_ground, train_text, val_text, test_text = dl.load_data(dataset=dataset)\n",
    "# _, _, _, train_ground, val_ground, test_ground, _,_,_,train_text, val_text, test_text= dl.load_data(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'LFs/'+dataset+'/val_5_dict_dt1/normal_reef.npy'\n",
    "train_reef = np.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , ..., 0.5       , 0.10919017,\n",
       "       0.5       ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an LSTM Model\n",
    "We now train a simple LSTM model with the labels generated by Reef. The following hyperparameter search is simplistic, and a more fine-tuned search and a more complex model can improve performance!\n",
    "\n",
    "__Note that this takes ~1 hour to run on CPU__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , ..., 0.5       , 0.10919017,\n",
       "       0.5       ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size is 7070\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           226240    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 279,541\n",
      "Trainable params: 279,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1278 samples, validate on 142 samples\n",
      "Epoch 1/2\n",
      "1278/1278 [==============================] - 15s 12ms/step - loss: 0.6854 - acc: 0.0000e+00 - val_loss: 0.6899 - val_acc: 0.5282\n",
      "Epoch 2/2\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6785 - acc: 0.0000e+00 - val_loss: 0.6827 - val_acc: 0.5282\n",
      "Accuracy: 52.82%\n",
      "y_pred is [[0.41319665]\n",
      " [0.36235878]\n",
      " [0.4169954 ]\n",
      " [0.40146738]\n",
      " [0.39294773]\n",
      " [0.42002702]\n",
      " [0.41763175]\n",
      " [0.41200954]\n",
      " [0.42405263]\n",
      " [0.39624783]\n",
      " [0.40763086]\n",
      " [0.380326  ]\n",
      " [0.4175263 ]\n",
      " [0.4358037 ]\n",
      " [0.40953234]\n",
      " [0.37354743]\n",
      " [0.41070586]\n",
      " [0.3885081 ]\n",
      " [0.38663593]\n",
      " [0.38320348]\n",
      " [0.41984335]\n",
      " [0.38673803]\n",
      " [0.35382566]\n",
      " [0.3804725 ]\n",
      " [0.404315  ]\n",
      " [0.37190655]\n",
      " [0.4345325 ]\n",
      " [0.43024245]\n",
      " [0.41720146]\n",
      " [0.4507519 ]\n",
      " [0.3526809 ]\n",
      " [0.39617983]\n",
      " [0.40299985]\n",
      " [0.44992632]\n",
      " [0.42534465]\n",
      " [0.4174543 ]\n",
      " [0.39315882]\n",
      " [0.4139671 ]\n",
      " [0.37160274]\n",
      " [0.3998313 ]\n",
      " [0.40849978]\n",
      " [0.34375057]\n",
      " [0.4252364 ]\n",
      " [0.39717433]\n",
      " [0.40420124]\n",
      " [0.40894446]\n",
      " [0.39187047]\n",
      " [0.4050006 ]\n",
      " [0.39632374]\n",
      " [0.41833788]\n",
      " [0.36967263]\n",
      " [0.37678632]\n",
      " [0.42971727]\n",
      " [0.38573146]\n",
      " [0.3824471 ]\n",
      " [0.40439934]\n",
      " [0.40172133]\n",
      " [0.39660957]\n",
      " [0.42294958]\n",
      " [0.3877388 ]\n",
      " [0.37557173]\n",
      " [0.43624172]\n",
      " [0.39979896]\n",
      " [0.39908156]\n",
      " [0.4022593 ]\n",
      " [0.39360577]\n",
      " [0.41887572]\n",
      " [0.38698357]\n",
      " [0.35621294]\n",
      " [0.42231822]\n",
      " [0.39122188]\n",
      " [0.3832567 ]\n",
      " [0.38366738]\n",
      " [0.42729554]\n",
      " [0.41091558]\n",
      " [0.3974716 ]\n",
      " [0.36794218]\n",
      " [0.39993715]\n",
      " [0.3874005 ]\n",
      " [0.40915042]\n",
      " [0.411     ]\n",
      " [0.40077886]\n",
      " [0.42037702]\n",
      " [0.440475  ]\n",
      " [0.39690655]\n",
      " [0.39309698]\n",
      " [0.4606755 ]\n",
      " [0.40652376]\n",
      " [0.41937697]\n",
      " [0.36081526]\n",
      " [0.36164457]\n",
      " [0.40463376]\n",
      " [0.40561122]\n",
      " [0.38333517]\n",
      " [0.4097366 ]\n",
      " [0.43474323]\n",
      " [0.4272616 ]\n",
      " [0.4023328 ]\n",
      " [0.402745  ]\n",
      " [0.41332346]\n",
      " [0.37780613]\n",
      " [0.41300413]\n",
      " [0.4108977 ]\n",
      " [0.4005376 ]\n",
      " [0.4341679 ]\n",
      " [0.3855701 ]\n",
      " [0.42736554]\n",
      " [0.38811216]\n",
      " [0.39512336]\n",
      " [0.4163244 ]\n",
      " [0.41325054]\n",
      " [0.38875023]\n",
      " [0.40599748]\n",
      " [0.4375161 ]\n",
      " [0.40126976]\n",
      " [0.3770948 ]\n",
      " [0.41056007]\n",
      " [0.34895045]\n",
      " [0.37886697]\n",
      " [0.4216981 ]\n",
      " [0.39851546]\n",
      " [0.39673007]\n",
      " [0.41989166]\n",
      " [0.38631684]\n",
      " [0.40584397]\n",
      " [0.40703678]\n",
      " [0.3896484 ]\n",
      " [0.42341703]\n",
      " [0.42157808]\n",
      " [0.4254406 ]\n",
      " [0.41780138]\n",
      " [0.41822615]\n",
      " [0.40748188]\n",
      " [0.37202305]\n",
      " [0.40239486]\n",
      " [0.4287202 ]\n",
      " [0.42608535]\n",
      " [0.41760415]\n",
      " [0.37826374]\n",
      " [0.41124806]\n",
      " [0.398832  ]\n",
      " [0.4115199 ]]\n"
     ]
    }
   ],
   "source": [
    "f1_all = []\n",
    "pr_all = []\n",
    "re_all = []\n",
    "val_acc_all = []\n",
    "\n",
    "\n",
    "bs_arr = [64]#,128,256]\n",
    "n_epochs_arr = [2]#[5,10,25]\n",
    "\n",
    "for bs in bs_arr:\n",
    "    for n in n_epochs_arr:\n",
    "        y_pred = lstm_simple(train_text, train_reef, val_text, val_ground, bs=bs, n=n)\n",
    "#         print(y_pred)\n",
    "        predictions = np.round(y_pred)\n",
    "        \n",
    "        val_acc_all.append(np.sum(predictions == val_ground)/float(np.shape(val_ground)[0]))\n",
    "        f1_all.append(metrics.f1_score(val_ground, predictions,average=\"macro\"))\n",
    "        pr_all.append(metrics.precision_score(val_ground, predictions))\n",
    "        re_all.append(metrics.recall_score(val_ground, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Batch Size:  64\n",
      "Best Epochs:  25\n",
      "Validation F1 Score:  0.6756644518272426\n",
      "Validation Best Pr:  0.7555555555555555\n",
      "Validation Best Re:  0.5074626865671642\n"
     ]
    }
   ],
   "source": [
    "ii,jj = np.unravel_index(np.argmax(f1_all), (1,1))\n",
    "print('Best Batch Size: ', bs_arr[ii])\n",
    "print('Best Epochs: ', n_epochs_arr[jj])\n",
    "\n",
    "print('Validation F1 Score: ', max(f1_all))\n",
    "print('Validation Best Pr: ', pr_all[np.argmax(f1_all)])\n",
    "print('Validation Best Re: ', re_all[np.argmax(f1_all)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance\n",
    "We re-train the model with the best validation performance since we don't save weights for the models currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           256288    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 309,589\n",
      "Trainable params: 309,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1278 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "1278/1278 [==============================] - 16s 12ms/step - loss: 0.6856 - acc: 0.0000e+00 - val_loss: 0.6907 - val_acc: 0.5260\n",
      "Epoch 2/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6782 - acc: 0.0000e+00 - val_loss: 0.6813 - val_acc: 0.5260\n",
      "Epoch 3/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6495 - acc: 0.0000e+00 - val_loss: 0.6078 - val_acc: 0.7040\n",
      "Epoch 4/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6262 - acc: 0.0000e+00 - val_loss: 0.6332 - val_acc: 0.6500\n",
      "Epoch 5/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6167 - acc: 0.0000e+00 - val_loss: 0.6168 - val_acc: 0.6700\n",
      "Epoch 6/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6112 - acc: 0.0000e+00 - val_loss: 0.6169 - val_acc: 0.6600\n",
      "Epoch 7/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6088 - acc: 0.0000e+00 - val_loss: 0.6225 - val_acc: 0.6680\n",
      "Epoch 8/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6074 - acc: 0.0000e+00 - val_loss: 0.6234 - val_acc: 0.6600\n",
      "Epoch 9/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6059 - acc: 0.0000e+00 - val_loss: 0.6203 - val_acc: 0.6660\n",
      "Epoch 10/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6052 - acc: 0.0000e+00 - val_loss: 0.6187 - val_acc: 0.6400\n",
      "Epoch 11/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6084 - acc: 0.0000e+00 - val_loss: 0.6408 - val_acc: 0.6260\n",
      "Epoch 12/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6127 - acc: 0.0000e+00 - val_loss: 0.6282 - val_acc: 0.6580\n",
      "Epoch 13/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6084 - acc: 0.0000e+00 - val_loss: 0.6285 - val_acc: 0.6480\n",
      "Epoch 14/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6057 - acc: 0.0000e+00 - val_loss: 0.6224 - val_acc: 0.6500\n",
      "Epoch 15/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6043 - acc: 0.0000e+00 - val_loss: 0.6231 - val_acc: 0.6540\n",
      "Epoch 16/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6036 - acc: 0.0000e+00 - val_loss: 0.6259 - val_acc: 0.6600\n",
      "Epoch 17/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6034 - acc: 0.0000e+00 - val_loss: 0.6224 - val_acc: 0.6440\n",
      "Epoch 18/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6033 - acc: 0.0000e+00 - val_loss: 0.6243 - val_acc: 0.6560\n",
      "Epoch 19/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6032 - acc: 0.0000e+00 - val_loss: 0.6238 - val_acc: 0.6500\n",
      "Epoch 20/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6237 - val_acc: 0.6460\n",
      "Epoch 21/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6236 - val_acc: 0.6500\n",
      "Epoch 22/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6244 - val_acc: 0.6480\n",
      "Epoch 23/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6225 - val_acc: 0.6500\n",
      "Epoch 24/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6246 - val_acc: 0.6480\n",
      "Epoch 25/25\n",
      "1278/1278 [==============================] - 14s 11ms/step - loss: 0.6031 - acc: 0.0000e+00 - val_loss: 0.6234 - val_acc: 0.6460\n",
      "Accuracy: 64.60%\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_simple(train_text, train_reef, test_text, test_ground, bs=bs_arr[ii], n=n_epochs_arr[jj])\n",
    "predictions = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score:  0.6231974147510762\n",
      "Test Precision:  0.7142857142857143\n",
      "Test Recall:  0.4219409282700422\n"
     ]
    }
   ],
   "source": [
    "print ('Test F1 Score: ', metrics.f1_score(test_ground, predictions, average='macro'))\n",
    "print ('Test Precision: ', metrics.precision_score(test_ground, predictions))\n",
    "print ('Test Recall: ', metrics.recall_score(test_ground, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Ground Truth Performance\n",
    "We can also train the same model with ground truth labels for the train set to see how far Reef labels are from the best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           256288    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 309,589\n",
      "Trainable params: 309,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1278 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "1278/1278 [==============================] - 9s 7ms/step - loss: 0.6896 - acc: 0.5383 - val_loss: 0.6889 - val_acc: 0.5260\n",
      "Epoch 2/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.6761 - acc: 0.5415 - val_loss: 0.6758 - val_acc: 0.5260\n",
      "Epoch 3/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.6426 - acc: 0.6706 - val_loss: 0.6346 - val_acc: 0.7860\n",
      "Epoch 4/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.6002 - acc: 0.9218 - val_loss: 0.6397 - val_acc: 0.7560\n",
      "Epoch 5/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.5798 - acc: 0.9241 - val_loss: 0.6207 - val_acc: 0.7680\n",
      "Epoch 6/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.5280 - acc: 0.9335 - val_loss: 0.5829 - val_acc: 0.7800\n",
      "Epoch 7/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.4303 - acc: 0.9429 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.2782 - acc: 0.9570 - val_loss: 0.3994 - val_acc: 0.8360\n",
      "Epoch 9/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.1648 - acc: 0.9656 - val_loss: 0.3736 - val_acc: 0.8580\n",
      "Epoch 10/10\n",
      "1278/1278 [==============================] - 8s 6ms/step - loss: 0.1280 - acc: 0.9609 - val_loss: 0.7764 - val_acc: 0.6920\n",
      "Accuracy: 69.20%\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_simple(train_text, train_ground, test_text, test_ground, bs=128, n=10)\n",
    "predictions = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score:  0.6461397058823529\n",
      "Test Precision:  1.0\n",
      "Test Recall:  0.350210970464135\n"
     ]
    }
   ],
   "source": [
    "print ('Test F1 Score: ', metrics.f1_score(test_ground, predictions, average='macro'))\n",
    "print ('Test Precision: ', metrics.precision_score(test_ground, predictions))\n",
    "print ('Test Recall: ', metrics.recall_score(test_ground, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
